# 数据存储对外技术说明文档

> \*版本为功能版本，对于一期、二期需求，一期版本为1.0，二期为2.0

|  版本  |  日期  |  变更人员  |  变更原因  |  变更内容  |  备注  |
| --- | --- | --- | --- | --- | --- |
|  1.0  |  20240814  |  孙洋   |  1.  初始化       |  1.  初始化       |  提供存储服务全局的对外技术说明文档  |
|   |   |   |   |   |   |

## 1 引言

### 1.1 编写目标

本文档旨在为用户提供Hyperchain平台存储系统的设计理念和技术实现细节，以便更好地理解和利用该平台。

文档中的图 在线地址为：

[https://drive.google.com/file/d/1D2j8puMd8n19DCFuAcC9vv\_CiAhFKnlb/view?usp=sharing](https://drive.google.com/file/d/1D2j8puMd8n19DCFuAcC9vv_CiAhFKnlb/view?usp=sharing)

### 1.2 阅读对象

本文档的目标读者包括Hyperchain平台的用户、开发者、运维人员和技术决策者。

## 2 系统概述

在Hyperchain架构中，数据被细分为两大范畴：链上数据与链下数据，每类数据下又进一步细分为特定的子类型，以满足不同场景下的存储与处理需求。

链上数据构成了区块链的核心记录，分为链上键值（KV）数据与链上区块型数据。链上KV型数据涵盖了系统的元数据实体，具体包括但不限于：**账户元数据、智能合约状态信息及区块链索引元数据**，这些是支撑系统运作的基础信息。链上区块型数据则封装了区块链的结构化单元——**区块体及其执行日志**，每个区块作为一个不可篡改的交易容器，封装了一系列经过验证的交易记录，并伴生执行这些交易过程中的日志信息。值得注意的是，Hyperchain创新性地将交易回执设计为与区块结构相似的格式，确保了执行结果与原始交易的高度耦合与可追溯性，深化了数据的完整性和透明度。

链下数据则扮演了辅助与缓冲的角色，分为链下KV型数据与链下暂存数据两大部分。链下KV型数据存储了对于系统共识机制至关重要的数据，如**共识状态信息、违规交易记录及网络成员的身份认证资料**，这些数据虽不直接构成区块链的主体部分，但对维护网络的安全性与合规性至关重要。至于链下暂存数据，则汇聚了来自MQ消息队列与Radar监控服务的待处理信息，这些信息源自Hyperchain系统但在正式链上确认前暂时缓存。此外，该类别还覆盖了在区块同步流程中从对等节点获取、尚未整合至本地区块链的区块副本，以及用于高效检索验证的**布隆过滤器元数据**，这一设计优化了数据同步的效率与精确度。

Hyperchain通过精细的数据分类与管理策略，不仅确保了核心链上数据的完整性和安全性，也通过高效的链下数据处理机制，增强了系统的响应速度与扩展能力，展现了其在数据处理层面的先进性和灵活性。

### 2.1 存储服务

Hyperchain平台旨在构建一个高度分布化、强健可用的数据存储生态系统，专为应对接踵而至的海量数据挑战而量身定制，特别是针对融合连续型数据与键值型数据的复合存储需求。针对传统区块链技术在数据存储能力上存在的根本性局限，本平台开创性地引入了一种混合式存储架构设计，这一设计精髓在于其精密优化了多种数据类型差异化存储机制，确保了对每种数据特性的精准适配与高效管理，架构示意图如下所示：

此架构通过深度整合分布式账本技术的去中心化优势与先进的数据分片、索引策略，不仅强化了数据的透明度与不可篡改性，还显著提升了系统的扩展性与响应效率，特别是在处理复杂异构数据集时展现出卓越性能。通过智能化的数据分流与归档机制，Hyperchain确保连续数据流与关键价值信息得以在保持即时访问性的同时，亦能有效应对未来潜在的数据膨胀，从而为各类应用场景铺设了坚实的数据基础架构支撑。

简而言之，Hyperchain平台代表了向新一代数据管理范式的重大跃进，它不仅重塑了我们对于大数据处理与存储的认知边界，更为探索区块链技术在超大规模数据环境下的新应用路径开辟了广阔前景。

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/eLbnj8PQLBQwOaNY/img/51ec375c-75cc-4a24-81dc-ae8e67805a6e.png)

针对连续性数据流，尤其是遵循“追加-only”策略的区块数据与交易确认信息，本平台创新性地设计并实施了专有的Filelog存储引擎。Filelog深度优化了面向追加操作的写入流程，确保了极致的写入吞吐量与无损的数据完整性，为持续增长的数据流提供了高效的存储解决方案。

在处理区块链状态数据这一关键领域，考虑到其对高频随机写入及快速顺序读取的严苛要求，平台经过精心评估后集成了LevelDB这一高性能键值存储系统。LevelDB因其在随机写入和顺序读取方面的杰出表现而广受赞誉，为应对日益严峻的I/O性能挑战提供了可靠的基石。在此基础上，为了进一步增强状态数据管理的效率与响应能力，平台融入了先进的多级缓存架构（Multicache），该架构通过智能化的分层管理和前瞻性的数据预取策略，在数据量急剧扩张的动态环境中，确保系统维持巅峰的读写性能，实现了资源优化配置与访问延迟最小化的核心诉求。

这一连串技术升级与创新，不仅成功突破了传统存储模型的性能瓶颈，更为构筑高性能、高度可扩展的区块链应用程序框架铺设了坚实的底层基础设施，彰显了技术前沿探索与实践的深刻洞察。

## 2.2 架构概述

通过实施数据的分域存储策略，每类数据在其专属的数据库中独立存放，这一举措不仅促进了数据架构的优化。它允许各类数据依据其独特的特征与需求，选用最适宜的数据库模型，从而优化存储效率与查询性能。此外，该设计还显著增强了系统的灵活性与可扩展性；一旦需要对某一数据集的存储解决方案进行升级或切换至其他类型的数据库系统，此架构能极大简化迁移过程，减小对整体系统的干扰。

为进一步提升Hyperchain平台对多样化数据库管理的一致性与便捷性，我们引入了“FlatoDB接口抽象层”。这一设计精髓在于，它构筑了一套统一的接口协议，无缝桥接并封装了底层多样化的数据存储库，实现了对不同数据库操作的标准化与抽象化。因此，无论底层数据库架构如何变动，Hyperchain平台皆能通过FlatoDB接口层实现高效、统一的数据交互，确保了高层业务逻辑的稳定性和连续性，同时也为未来可能的数据库技术迭代预留了灵活的对接入口，展现了高度的前瞻性和技术适应能力。下图展示了这一先进架构的设计概览。

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/eLbnj8PQLBQwOaNY/img/81076ac0-d387-4937-8036-5d61e7060636.png)

### 2.3 关键特点

#### 2.3.1 LevelDB

LevelDB作为一款高性能的键值对（Key-Value, KV）型嵌入式数据库系统，在当前技术领域内广受青睐，特别是在处理随机读写密集型应用场景时展现出卓越效能。其设计精髓在于高效应对无序键访问，即在交易执行情境下，无论是查询现有记录还是预写未决数据，LevelDB均能确保操作的低延迟与高吞吐量。

在Hyperchain架构中，LevelDB的应用被细分为四个关键数据库实体：**ConsensusDB**负责维护核心共识状态，确保分布式网络中的一致性与可靠性；**MQDB**与**RadarDB**则分别用于存档消息队列（Message Queue, MQ）与雷达监控服务产生的动态信息，这两个组件是确保系统消息传递及时性和网络监控精确性的基石；**CertDB**专门用于保管认证证书，这些证书构成了系统安全与权限管理的基础。

LevelDB的核心特性可归纳为：

1.  **高效的随机访问能力**：由于其设计允许对无序键进行快速检索，LevelDB特别适合处理不可预测的访问模式，确保数据读写操作的高效执行。
    
2.  **数据持久性与自我恢复机制**：特别是对于CertDB而言，其存储的信息独立于区块链区块结构，无需与特定区块绑定，从而简化了数据管理复杂度。而对于其他数据库，即便遭遇短暂的数据异常，系统通过后续流程亦能自动校正，保证数据完整性。
    
3.  **轻量级数据单元管理**：LevelDB优化了对小规模数据项的处理，这在处理大量细粒度信息时尤为重要，有助于减少资源消耗并提升整体性能。
    

采用LevelDB而非轻量级文件系统如Minifile，基于深思熟虑的技术考量。尽管Minifile适用于短期或临时数据存储，但Hyperchain所涉及的数据库内容具有长期保存价值与持续更新需求。LevelDB凭借其高度优化的磁盘I/O策略、日志结构化存储以及强大的数据持久化机制，能够更好地满足这一系列严格要求，确保数据的安全性、一致性和长期可访问性，从而为Hyperchain平台提供坚实的底层数据支撑。

#### 2.3.2 Multicache

在Hyperchain架构中，Multicache扮演了一个核心角色，它是一种复合型数据存储解决方案，集成了高性能的读写缓存机制与分布式LevelDB数据库引擎。此设计旨在通过智能化的资源管理和数据组织策略，显著增强系统的整体性能与灵活性。具体特性阐述如下：

1.  **高效的内存缓冲策略**：Multicache利用了精心配置的内存空间作为高速缓存区，将原本直接针对LevelDB的写操作先行转换为内存写入。这一机制有效利用了内存的高速访问特性，减少了磁盘I/O开销，从而大幅度提高了写操作的执行效率。此过程在系统资源管理层面实现了智能的内存与外存数据交换策略，确保了资源的高效利用。
    
2.  **优化的时间局部性利用**：针对具有明显时间局部性的应用场景，Multicache特别设计的缓存策略能够有效捕捉并保留最近写入的数据。当系统执行读操作时，这部分数据可以直接从内存缓存中快速检索，极大缩短了读取延迟，进一步提升了整体的读取性能。这种机制是对时间局部性原理的高效应用，强化了系统对高频访问数据的响应能力。
    
3.  **增强的数据管理与追溯性**：Multicache通过将数据与唯一的sequence number关联，引入了一种高级的数据版本控制机制。这不仅为数据变更提供了精确的追踪途径，还为Hyperchain中的状态恢复或事务回滚功能奠定了坚实基础，确保了数据完整性和一致性，尤其是在面对复杂并发场景和故障恢复需求时展现出高度的可靠性和灵活性。
    
4.  **分布式LevelDB的创新部署**：针对传统单实例LevelDB可能面临的扩展性瓶颈，Multicache采取了创新策略，将底层LevelDB数据库横向拆分为多个独立实例。这一设计不仅分散了存储负载，增强了系统的水平扩展能力，还为处理高并发请求和大规模数据集提供了强大的支撑框架。
    
5.  **资源管理的考量与挑战**：尽管多实例LevelDB架构带来了显著的性能与扩展优势，但也对系统资源管理提出了更高要求，尤其是文件句柄资源的消耗成为不容忽视的问题。每个LevelDB实例均需占用一定数量的文件句柄，随着实例数量的增长，系统可能会面临文件句柄资源枯竭的风险。因此，如何高效管理和优化这一稀缺资源，成为了实现Multicache设计目标中的一个重要考量因素，也是未来优化方向之一。
    

综上所述，Multicache通过其精妙的设计，不仅在技术层面上实现了对Hyperchain数据处理能力的显著提升，也展示了在面对现代区块链平台所面临的性能与扩展性挑战时的创新思路与解决方案。

##### 存储数据及特点介绍

Flato-DB采用了一组精心设计的Multicache数据库来支撑其复杂的分布式账本操作，这一架构内嵌了三大核心组件：StateDB、AccountDB与ChainDB，每部分承担着独特而关键的角色。StateDB专注于收纳由智能合约执行过程中衍生的状态信息，确保了业务逻辑的持久化状态。AccountDB则致力于维护交易执行成果下的账户元数据，保障账户状态的即时更新与查询。至于ChainDB，则是负责存储区块链的元数据，包括但不限于链上高度、区块及交易的索引信息，为区块链的结构化信息提供高效存取。

这些数据库采纳了键值对（Key-Value, KV）模型，以此来优化数据的存取效率。在数据提交至Multicache层次时，实施了一种区块级的数据聚合策略，即同区块生成的同类数据会被逻辑整合，并严格绑定其所属的区块编号，这种机制增强了数据的一致性和可追溯性。

针对数据管理特性，Flato-DB的Multicache设计充分考虑了以下高级需求：

1.  **随机存取优化**：鉴于交易处理的动态性，系统设计适应了无序键访问的需求，确保无论是对现有记录的查询还是新记录的创建，都能实现高效的随机读写操作。这种设计直面了去中心化应用中数据访问模式的不确定性挑战。
    
2.  **区块级数据可追溯与回滚能力**：系统内置了高度灵活的数据版本控制机制，使得在遇到异常区块情况时，能基于区块编号逆向执行数据回滚操作。这一特性对于维护区块链的完整性和一致性至关重要，体现了Flato-DB对区块链事务原子性与一致性的坚定支持。
    
3.  **细粒度数据管理**：认识到单个账户状态或交易状态信息的相对轻量级特性，Flato-DB优化了存储架构以高效处理此类小规模数据单元，减少了不必要的存储开销，同时提升了数据处理速度，确保了即使在高并发环境下也能维持系统的高性能运行。
    

综上所述，Flato-DB通过其先进的Multicache数据库体系，不仅实现了对区块链数据管理的高度优化，还确保了在复杂分布式环境下的数据可靠性和操作灵活性，为构建高性能、强一致性的区块链应用提供了坚实的基础。

##### 使用优点分析

1、Multicache通过智能地分割底层LevelDB数据库，有效遏制了单一实例因数据量膨胀而导致的性能衰退问题，增强了系统的可伸缩性和自主管理能力。这一设计不仅为未来应对大规模数据增长时实现磁盘分区存储及无缝扩展LevelDB数量以支撑扩容需求奠定了坚实基础，还进一步优化了资源调配与管理的灵活性。

2、相较于市面上的现成键值对存储解决方案，Multicache在支持区块级回滚操作方面展现出显著优势。它提供了更为精细化的控制能力和高效的数据恢复机制，确保了在复杂数据管理场景下的高可用性和一致性。

3、Multicache巧妙利用了分配的内存空间，通过将写操作缓存化，即直接将写入请求转化为内存写入，极大提高了数据写入的效率。这种“内存优先”的策略显著减少了I/O瓶颈，加速了数据处理流程，是针对高性能数据库系统优化的一项关键技术创新。

4、通过严谨地应用Multicache——仅针对那些具有回滚需求并深度融入核心业务流程的三个关键数据库实施此策略，系统在确保高级功能实现的同时，也实现了对文件句柄等系统资源的精细控制与有效管理。此举有效避免了资源过度消耗的问题，展现了在复杂系统设计中平衡性能与资源使用的高超技艺。

#### 2.3.3 Filelog

Filelog作为一种先进的数据存储方案，在flato-db架构中扮演着核心角色，尤其是在处理高吞吐量、大数据块的存取场景中展现出显著优势。其设计围绕严格递增的键（key）策略展开，确保了数据的有序性和唯一性，每个写入操作关联一个不可逆的、单调递增的序列号（sequence number），这一机制从根本上杜绝了重复或逆序写入的可能，保障了数据的时间线性一致性和完整性。

##### 存储数据及特点介绍

Flato-DB包含三个专门设计的Filelog数据库组件：BlockFilelog、Journal与ReceiptFilelog，分别用以保管区块链数据、日志信息及交易回执。这些数据库采用区块编号作为索引键，确保数据的精确定位。以下是这些组件运作机制的详细阐述，采用了更为精确的专业术语：

1、**顺序写入机制（Sequential Write Protocol）**：系统实施了一种严格有序的数据记录策略，每一项数据记录均关联一个独一无二且递增的序列号（sequence number）。这一设计确保了新录入数据的序列号总是大于此前所有记录，排除了对已确认序列号或更低序号数据的重复写入请求，从而维护了时间序列上的一致性和完整性。

2、**随机访问读取（Random Access Read Capability）**：尽管写入操作遵循严格的顺序规则，Flato-DB设计允许对任意序列号所对应的数据进行高效、非连续性的检索。这意味着，无论数据在链上的位置如何，系统都能迅速响应读取请求，提升了数据处理的灵活性和效率。

3、**数据迁移与归档支持（Data Migration and Archival Support）**：Flato-DB内置了对历史数据管理的先进解决方案，即数据归档功能。此特性使得存储于线上环境的历史数据能够被无缝转移到离线存储路径中，优化资源分配，减轻在线存储负担，同时也为长期数据保存与合规性需求提供了有力支持。

4、**大对象存储优化（Optimization for Large Object Storage）**：鉴于区块链数据的特性，单个数据条目（如完整区块信息）经常规模庞大，不易压缩至预设大小。Flato-DB对此进行了针对性设计，确保即使面对高维度、大体积数据时，也能保持高效的存储与访问性能，体现了系统在处理大数据块时的稳健性和扩展性。这要求底层架构对大对象存储具有高度的优化能力，包括但不限于高效的磁盘I/O管理、智能缓存策略及分布式存储技术的应用。

##### 使用优点分析

相较于LevelDB等通用键值存储系统，Filelog在处理大体积数据条目时展现出更高的读写效率，归因于其对大对象存储的优化策略以及直接文件操作带来的数据迁移效率提升。这种设计不仅克服了传统数据库在处理大规模、高密度数据时的性能瓶颈，还为需要频繁执行数据分层、归档操作的应用场景提供了强有力的支撑。因此，Filelog不仅是flato-db架构中不可或缺的组件，也是面向未来大数据处理、长期数据保留策略的理想选择。

#### 2.3.4 Minifile

Minifile 在 Flato 框架中作为一种临时数据存储解决方案，利用了一个简单但巧妙设计的架构。每一个键值对在 Minifile 系统中都被精心映射到一个独立的文件，从而在数据条目与底层文件结构之间建立了直接的关联。Flato 的内部机制确保了键字符串的不可侵犯性，通过排除空字符（\0）的使用，这些字符可能会破坏文件命名规范，从而维护了文件系统的完整性，并确保了与标准文件命名惯例的兼容性。

这种方法不仅增强了数据的弹性，还通过利用基于文件的存储系统的固有效率来优化读写操作。通过限制键值不包含空字符终结符，Flato 优雅地规避了文件系统的限制，体现了对数据安全性和性能优化的深思熟虑的设计理念。这种机制突显了 Flato 对于稳健数据管理的承诺，在不牺牲数据一致性或访问速度的前提下，实现了对数据临时性的无缝管理。

##### 存储数据及特点介绍

在Flato架构中，我们设计并实现了四个专有化的Minifile数据库，旨在优化系统性能与数据管理效率。这些数据库各司其职，精准服务于不同的功能需求：

1.  **Sync Minifile**：该数据库专门用于暂存从网络中其他节点同步而来的数据片段，这些数据在`sync-chain`过程中扮演关键角色。考虑到同步数据可能因网络因素出现非顺序到达的情况，此数据库需支持高效的随机写入与随机读取操作。尤为重要的是，一旦数据被顺序处理并确认无误后，实施立即删除策略以维护存储资源的有效周转，体现了对动态数据管理的“即时处理-清除”(Just-In-Time Processing and Purge)机制。
    
2.  **Bloom Filter Minifile**：为了加速交易验证并避免重复处理，此数据库存储了一套布隆过滤器。这些过滤器通过概率算法高效识别并剔除重复交易，显著提升系统吞吐量。随着时间推移或数据积累至预设阈值，布隆过滤器会执行周期性清理，采用“老化淘汰”(Age-based Eviction)策略，确保内存占用维持在合理水平，此过程体现了对资源的有序释放与管理优化。
    
3.  **Consensus Minifile**：核心聚焦于共识机制的稳健性，此数据库负责保管交易打包形成的批次（Batches）以及接收到的共识结果。这些批次数据主要是为了系统故障恢复之需，故常态下访问频率极低。然而，随着共识过程的不断推进及批次的确认完成，相关数据将按顺序被淘汰，实施“事务终态清除”(Transaction Finality Purging)，这一机制确保了数据库不会无限膨胀，同时保持了对于历史数据的精确管理和最小化存储占用。
    

这四个Minifile数据库的设计，通过集成随机访问优化、高效数据去重机制、以及面向终态一致性的数据生命周期管理，展现了Flato系统在分布式环境下的高度优化与自适应能力，确保了数据处理的高效性、准确性和资源使用的高效可持续性。

##### 使用优点分析

鉴于这些数据集特性包含顺序删除操作的频繁需求，filelog机制在应对此类操作时显得力有不逮，因其要求额外的处理流程以维护数据一致性与完整性，这无疑增加了实现的复杂度与资源开销。此外，考虑到每条记录的数据体量（例如，单一区块或布隆过滤器）颇为可观，而总体记录条数相对有限，这种数据分布特性指向了一种特定的存储优化需求。

相较于诸如LevelDB等广泛应用的键值存储系统，采用单文件大对象存储模式可能在性能表现上更为优越。此模式规避了传统数据库为大量细碎数据条目设计的索引管理开销，直接以连续大块数据的形式存储，不仅减少了磁盘寻址次数，还提升了I/O效率与读写吞吐量。因此，在此场景下，选择支持大对象存储、优化连续写入与稀疏访问模式的数据库解决方案，将更加契合高效数据管理和访问的需求，从而确保系统整体性能与资源利用的最大化。